{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-palestinian",
   "metadata": {},
   "source": [
    "<img src=\"../images/SentimentAnalysisBadge.png\" alt=\"Chronicling America Search Example\" width=\"150px\" style=\"border:1px solid black;\" align=\"right\">\n",
    "\n",
    "# Badge 2 - Sentiment Analysis\n",
    "\n",
    "What you'll learn in this Notebook:\n",
    "\n",
    "- What sentiment analysis is\n",
    "- How it works\n",
    "- How to run it yourself\n",
    "- How to run it on a dataset and visualise the overall output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-washington",
   "metadata": {},
   "source": [
    "## 1. What is Sentiment Analysis and where is it used?\n",
    "\n",
    "Sentiment analysis is a computational technique used for analysing text to determine its sentiment, for example, whether the text conveys positive, negative or neutral sentiment.\n",
    "\n",
    "It is often used in commercial settings (and sometimes called opionion mining) and is applied to social media, online review data or surveys, for example, to determine automatically how customers or people express themselves about different brands or products and to analyse what positive and negative words they are using to express themselves.  During political elections sentiment analysis is also used to determine how people feel about different parties and candidates.\n",
    "\n",
    "Large amounts of social media data, like Twitter Tweets or Reddits posts, can be analysed in this way to determine trends over time and monitor where things work well or go wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-governor",
   "metadata": {},
   "source": [
    "## 2. How does it work?\n",
    "\n",
    "There are different methods used for performing sentiment analysis.  For example, there are lexicon-lookup methods where each word in a piece of text is checked automatically against a lexicon of positive and negative words to see if it appear in that lexicon.  The more positive or negative words occur the stronger is the sentiment each way.  In this course you will learn how to use a lexicon-based method.\n",
    "\n",
    "There are also machine learning and deep learning methods that can be applied to sentiment analysis. This is where data annotated for sentiment by humans is used to train a model which can then be used to classify new data based on what it has learned during training.  We won't cover these approaches in this course, but if you are interested in such learning-based methods which are able to consider the context, as well as representing the meanings of the words in the text mathematically, then check out the two sources below by Lui (2020) and Agarwal et al., (2020).\n",
    "\n",
    "- Liu, B., 2020. Sentiment analysis: Mining opinions, sentiments, and emotions. Cambridge University Press. https://doi.org/10.1017/9781108639286\n",
    "- Agarwal, B., Nayak, R., Mittal, N. and Patnaik, S. eds., 2020. Deep learning-based approaches for sentiment analysis. Singapore: Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-undergraduate",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis using TextBlob\n",
    "\n",
    "In this course you'll learn how to use [TextBlob](https://textblob.readthedocs.io/en/dev/) for sentiment analysis. TextBlob is a Python library developed to work with another natural language processing (NLP) tool called the Natural Language Toolkit ([NLTK](https://www.nltk.org)).  NLTK provides access to the lexicons which are required for computing sentiment. So TextBlob uses a lexicon-based approach for performing sentiment analysis.\n",
    "\n",
    "TextBlob computes sentiment using two values: polarity and subjectivity.  \n",
    "\n",
    "**Polarity** is a value between 1 and -1. The closer the value is to 1, the more positive the sentiment of the text is considered to be.  The closer the value is to -1, the more negative it is.  \n",
    "\n",
    "**Subjectivity** represents whether a piece of text is more of a personal opinion or something more factual. The subjectivity value lies between 0 and 1.  The closer it is to 1, the more subjective the text is and the closer it is to 0 the more factual it is.\n",
    "\n",
    "Imagine your friend says to you \"I really hate this day. Everything is going wrong.\" The sentiment of their utterance is overall very negative in polarity, but their statement is also quite subjective.\n",
    "\n",
    "Let's see how TextBlob works in action ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-cooling",
   "metadata": {},
   "source": [
    "## 4. Running a Sentiment Analyser\n",
    "\n",
    "### Installing the tool\n",
    "\n",
    "You first need to install TextBlob, the sentiment analysis tool we're using on this course, onto your own computer.  To install it you just need to run the following line of code.  Note that this may take a while and will generate some messages (and sometimes warnings) when installing all the libraries that are needed. Once the code cell finishes running (i.e. the asterix in the square bracket changes to a number),  move onto the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-egyptian",
   "metadata": {},
   "source": [
    "### Importing the tool\n",
    "\n",
    "Next you have to import the library like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-spice",
   "metadata": {},
   "source": [
    "### Running the tool\n",
    "\n",
    "You can run TextBlob on piece of text using just one line of code and store the output in the ```blob``` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"He's not happy.\")\n",
    "print(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-quality",
   "metadata": {},
   "source": [
    "You can see that TextBlob is run by specifying an example sentence (\"He's not happy.\") in double quotes.  TextBlob actually computes various things besides sentiment.  The `blob` variable which we have just assigned stores the string you specified as well as all of the TextBlob output that was computed.  However, when printing the `blob` variable it doesn't give you the results, it only prints the text.\n",
    "\n",
    "So to examine what the sentiment is you need to call the `.sentiment` object attribute directly on the `blob` object and store its results in a new variable (e.g. `results`), which you can then print.\n",
    "\n",
    "An **object attribute** is a variable that belongs to one (and only one) object.  In our example, it (`.sentiment`) stores the sentiment results for the sentence \"He's not happy.\".\n",
    "\n",
    "You can also get the other information which TextBlob computes but calling other object attibutes (e.g. `.words` for the words, `.tags` for part-of-speech tags or `.noun_phrases` for noun phrases) but let's stick to sentiment in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = blob.sentiment\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-instrument",
   "metadata": {},
   "source": [
    "### üêõ Mini task 4.1\n",
    "You can experiment by changing words in this phrase and seeing how this changes the scores TextBlob produces (eg. \"He is quite happy\", \"He seems very happy\", \"He is not very happy\"). Don't forget use the code from the last two code cells above, first setting the new phrase to a TextBlob object and assigning it to the 'blob' variable and then to return the sentiment computed for the text assigned to `blob`.\n",
    "\n",
    "What kinds of words produce higher or lower polarity and subjectivity scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-jumping",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    blob = TextBlob(\"He is quite happy.\")\n",
    "    result = blob.sentiment\n",
    "    print(result)\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-providence",
   "metadata": {},
   "source": [
    "You can also compute sentiment for longer pieces of text. For example, let's check what sentiment scores are produced when we run TextBlob on what our friend said earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"I really hate this day. Everything is going wrong.\")\n",
    "result = blob.sentiment\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-denmark",
   "metadata": {},
   "source": [
    "TextBlob classifies these two sentences as fairly negative in terms of polarity, and also as highly subjective.\n",
    "\n",
    "Now let's look at how TextBlob works with negation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"I'm feeling not bad today.\")\n",
    "result = blob.sentiment\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-damage",
   "metadata": {},
   "source": [
    "TextBlob seems to recognise that there is negation in the sentence. \n",
    "Try some other examples to see if that's always the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-weekend",
   "metadata": {},
   "source": [
    "### üêõ Mini task 4.2\n",
    "\n",
    "Now write out the code for some examples of your own. Consult the code from the previous code cell but replace it with a different string of text, for example, \"Your pizzas are the best.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-silver",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    blob = TextBlob(\"Your pizzas are the best.\")\n",
    "    result = blob.sentiment\n",
    "    print(result)\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-attack",
   "metadata": {},
   "source": [
    "## 5. Running TextBlob on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-parker",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "We now need to load our own dataset into the notebook so that we can analyse it. You will remember that in the notebook we worked through earlier, we produced a tab-separated version of the babysitting story script, and saved it in the 'data' directory (folder). Take a look in that directory to make sure you can see it. It's called ```Babysitting-Act3-cleaned.tsv```.\n",
    "\n",
    "To load the file, we will import a library called `pandas`. We'll use pandas to read CSV and TSV files and store their information in column format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-facial",
   "metadata": {},
   "source": [
    "Our file contains two columns, the first containing the name of the speaker and the second containing what each speaker said.\n",
    "\n",
    "Pandas lets us read in the file as a data frame (like a table) using the ```read_table``` function.\n",
    "\n",
    "We can specify the names of the columns using the ```colnames``` variable, and also specify the column separator with ```sep``` (which we will set to \"\\t\" for tab in this case).\n",
    "\n",
    "We store this table in the ```df``` variable, short for data frame.\n",
    "\n",
    "We also specify the fact that the values in the text and speaker columns are strings (i.e. words not numbers).  We need to do this as TextBlob only accepts strings as input.\n",
    "\n",
    "The last line of code (```df.head()```) shows us the header and the first five rows of the data frame we have just created and loaded in pandas. Yay!\n",
    "\n",
    "(If you want to check more than 5 lines, type that number into the brackets after df.head. E.g. to see the first 10 lines, type (```df.head(10)```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the file as a table using pandas\n",
    "colnames=['speaker', 'utterance'] \n",
    "df = pd.read_table(\"../data/Babysitting-Act3-cleaned.tsv\", sep=\"\\t\", names=colnames)\n",
    "df['speaker'] = df['speaker'].astype(str)\n",
    "df['utterance'] = df['utterance'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-spain",
   "metadata": {},
   "source": [
    "Because some of the utterances are longer than a single sentence, let's split the transcript into sentences before computing sentiment.\n",
    "\n",
    "The following bit of code is a simple sentence splitter which splits each utterance string when it encounters a punctuation mark that normally marks the end of a sentence, such as a full stop, a question mark or an exclamation mark. It also expands the data frame so that each new sentence is on a new row, preceeded by its speaker.\n",
    "\n",
    "The last line gives the instruction to print the first 25 rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (df.pop('utterance')\n",
    "    .str.strip('.')\n",
    "    .str.strip('?')\n",
    "    .str.strip('!')\n",
    "    .str.split('[\\.\\?\\!]\\s+', expand=True)\n",
    "    .stack()\n",
    "    .rename('utterance')\n",
    "    .reset_index(level=1, drop=True))\n",
    "\n",
    "df = df.join(s).reset_index(drop=True)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-indonesian",
   "metadata": {},
   "source": [
    "In the leftmost column you can see an index for each line in the table, as well as the two columns for speaker and utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-pepper",
   "metadata": {},
   "source": [
    "You can use the ```describe()``` function to give you a summary of what's in the table. When you run the next line of code you will see that the table contains 348 rows and there are three unique speakers.  The speaker uttering the most sentences is Myron Jones and the most frequent utterance is ```Yeah```. Yeah. :-)\n",
    "\n",
    "The content of the utterance column is what we want to compute sentiment for. Let's do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-diamond",
   "metadata": {},
   "source": [
    "### Computing sentiment \n",
    "\n",
    "We will now compute the sentiment for each row of text.\n",
    "\n",
    "To do this we use two lambda functions to determine the polarity and subjectivity for each line of text in the data frame.\n",
    "\n",
    "A **lambda function** is a small anonymous function in Python.  It can take any number of arguments, but can only have one expression.\n",
    "\n",
    "We apply the lambda functions to each text cell in the data frame, and store their results in the data frame in two additional columns called polarity and subjectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing polarity and subjectivity for each line in the 'utterance' column\n",
    "polarity = lambda x: TextBlob(x).sentiment.polarity\n",
    "subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "df['polarity'] = df['utterance'].apply(polarity)\n",
    "df['subjectivity'] = df['utterance'].apply(subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-paste",
   "metadata": {},
   "source": [
    "### üêõ Minitask 5.1 \n",
    "\n",
    "Now check how the first few lines of the data frame look like.  Remember you can use the ```head()``` function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-monitor",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    df.head()\n",
    " \n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-raise",
   "metadata": {},
   "source": [
    "## 6. Visualising sentiment\n",
    "\n",
    "Now let's visualise sentiment so that we can display and understand the results more easily than trying to make sense of long columns of numbers.\n",
    "\n",
    "### Visualising each result by colour\n",
    "\n",
    "The following line of code visualises the polarity and subjectivity in the table using colours. It's quite a long line of code but all it does is set a colour background to the cells containing the sentiment scores.\n",
    "\n",
    "Polarity is displayed as a colour ranging between red, yellow and green, <font color=\"red\">red</font> signaling negative sentiment, <font color=\"green\">green</font> signalling positive sentiment and <font color=\"gold\">light orange</font> being neutral.  Subjectivity is displayed on a grey scale with white signalling statements deemed factual, and black signalling statements deemed subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-genre",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.style.background_gradient(subset='polarity', cmap='RdYlGn', axis=None).background_gradient(subset=['subjectivity'], cmap='Greys', axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-outreach",
   "metadata": {},
   "source": [
    "### üêõ Mini task 6.1\n",
    "\n",
    "Look at some of the individual rows and compare the positive or negative scores to the vocabulary used. How accurate does the sentiment analysis seem to you as a human reader? Where has it gone wrong, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-curtis",
   "metadata": {},
   "source": [
    "### Visualising sentiment in one graph\n",
    "\n",
    "We will now display the sentiment results for the entire story in a single graph. We'll plot polarity on the x-axis and subjectivity on the y-axis.\n",
    "\n",
    "You don't need to understand the following bit of code in detail, though I've added some explanations in the comments.  One thing to know is that we use a library called ```matplotlib``` for creating the graph. \n",
    "\n",
    "After an initial setup of the figure size, the code goes through the data frame to collect all the scores, store them in a list and display them on the graph, plotting each sentence as one polarity/subjectivity coordinate.\n",
    "\n",
    "The code also keeps track of instances when the same coordinates are repeated, so that pairs which occur frequently are displayed as larger dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results in one graph showing:\n",
    "# subjectivity on the y-axis\n",
    "# polarity on the x-axis\n",
    "\n",
    "# import matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# set up the size of the figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "# create two empty lists for the x and y coordinates\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "# add the polarity values as x coordinates and\n",
    "# the subjectivity values as the y coordinates\n",
    "for (index, row) in df.iterrows():\n",
    "    x.append(row.loc['polarity'])\n",
    "    y.append(row.loc['subjectivity'])\n",
    "\n",
    "# increase the dot size in case there are multiple coordinate pairs\n",
    "from collections import Counter\n",
    "# count the occurrences of each point\n",
    "c = Counter(zip(x,y))\n",
    "# create a list of the sizes, here multiplied by 10 for scale\n",
    "s = [10*c[(xx,yy)] for xx,yy in zip(x,y)]\n",
    "\n",
    "# make the scatter plot using gray as the colour for each dot\n",
    "plt.scatter(x, y, s, color='Gray')\n",
    "\n",
    "# specify the title\n",
    "plt.title('Sentiment Analysis', fontsize = 20)\n",
    "\n",
    "# set lables on axes\n",
    "plt.xlabel('‚Üê Negative ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî Positive ‚Üí', fontsize=15)\n",
    "plt.ylabel('‚Üê Facts ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî Opinions ‚Üí', fontsize=15)\n",
    "\n",
    "# set the x-axis range to the entire polarity range (-1.0 to 1.0)\n",
    "plt.xlim([-1.0, 1.0])\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-patrol",
   "metadata": {},
   "source": [
    "If we assume that the sentiment analysis is more or less accurate, we can conclude from this graph that, aside from the neutral utterances, the story tends towards beeing slightly more positive than negative, and is angled slightly more towards the subjective than the factual. How well does this accord with your own impressions of the story as a human reader?\n",
    "\n",
    "When companies do this kind of analysis (on texts other than literary ones), they are interested in these kind of trends and how they change over time, but they also want to see examples of particular outliers to see what customers are happy or unhappy about in terms of products and services.\n",
    "\n",
    "When doing literary analysis, however, we are likely to be interested in other aspects of a text. We might for instance want to examine sentiment by character or speaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-smith",
   "metadata": {},
   "source": [
    "### Visualising sentiment by speaker\n",
    "\n",
    "Here we create the same graph but using a different colour for each speaker.  Our data set contains three speakers: <font color=\"purple\">Ira Glass</font>, <font color=\"orange\">Myron Jones</font> and <font color=\"green\">Carol Jones</font>.\n",
    "\n",
    "You don't need to understand the following bit of code in detail, though I've added some explanations in the comments.  Essentially the only difference to the previous cell is that the code collects the data by speaker first before it plots it in the different colours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis by speaker\n",
    "\n",
    "# set up the size of the figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "# create empty x and y coordinate lists for each of the three speakers\n",
    "ira_x=[]\n",
    "ira_y=[]\n",
    "myron_x=[]\n",
    "myron_y=[]\n",
    "carol_x=[]\n",
    "carol_y=[]\n",
    "\n",
    "# loop through the data frame and assign the x and y coordinates\n",
    "# to the correct list depending on the speaker\n",
    "for (index, row) in df.iterrows():\n",
    "    x=row.loc['polarity']\n",
    "    y=row.loc['subjectivity']\n",
    "    speaker=row.loc['speaker']\n",
    "    if speaker == \"@Ira Glass\":\n",
    "        ira_x.append(x)\n",
    "        ira_y.append(y)\n",
    "    elif speaker == \"@Myron Jones\":\n",
    "        myron_x.append(x)\n",
    "        myron_y.append(y)\n",
    "    elif speaker == \"@Carol Jones\":\n",
    "        carol_x.append(x)\n",
    "        carol_y.append(y)\n",
    "\n",
    "# function to increase the dot size in case there are multiple coordinate pairs      \n",
    "def getSize(x,y):\n",
    "    # count the occurrences of each point\n",
    "    c = Counter(zip(x,y))\n",
    "    # create a list of the sizes, here multiplied by 10 for scale\n",
    "    s = [10*c[(xx,yy)] for xx,yy in zip(x,y)]\n",
    "    return s\n",
    "\n",
    "# create scatter plots by speaker\n",
    "ira = plt.scatter(ira_x, ira_y, s=getSize(ira_x,ira_y), color='Purple')\n",
    "myron = plt.scatter(myron_x, myron_y, s=getSize(myron_x,myron_y), color='Orange')\n",
    "carol = plt.scatter(carol_x, carol_y, s=getSize(carol_x,carol_y), color='Green')\n",
    "\n",
    "# specify the title\n",
    "plt.title('Sentiment Analysis by Speaker', fontsize = 20)\n",
    "\n",
    "# set lables of axes\n",
    "plt.xlabel('‚Üê Negative ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî Positive ‚Üí', fontsize=15)\n",
    "plt.ylabel('‚Üê Facts ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî Opinions ‚Üí', fontsize=15)\n",
    "\n",
    "# add legend\n",
    "lgnd = plt.legend((ira, myron, carol),\n",
    "           ('Ira Glass', 'Myron Jones', 'Carol Jones'),\n",
    "           loc='lower right')\n",
    "lgnd.set_title(\"Speakers\")\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([50.0])\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-temperature",
   "metadata": {},
   "source": [
    "You can see that Carol's utterances are represented as slightly more positive and subjective than those of Ira and Myron, although Carol is the person who speaks the least. You can work this out mathematically by determining the average scores per speaker and plotting them in a bar plot. This is done by grouping the data frame by speaker and polarity (or subjectivity) using the ```groupby()``` function. We'll first plot mean polarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate mean of sentiment score per speaker\n",
    "dfg = df.groupby(['speaker'])['polarity'].mean()\n",
    "\n",
    "#create a bar plot\n",
    "dfg.plot(color=['Green', 'Purple', 'Orange'], kind='bar', title='Mean Polarity Scores', ylabel='Polarity',\n",
    "         xlabel='Speaker', figsize=(12, 9), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-district",
   "metadata": {},
   "source": [
    "You can also plot the sentiment as a histogram and get a better idea of how each speaker's scores are distributed. After running the code below, you will see that Carol Jones's utterances are the most spread out in terms of their polarity, while Myron Jones's utterances are assessed as being mostly neutral to slightly positive. Ira Glass's utterances are mostly neutral, which perhaps makes sense as he is the interviewer. You can see how this kind of analysis can be used to build up what you might think of as the 'sentiment profile' of a character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "speakers = ['@Ira Glass','@Myron Jones','@Carol Jones']\n",
    "colours = ['Purple','Orange','Green']\n",
    "\n",
    "for index, speaker in enumerate(speakers):\n",
    "    df[df['speaker']==speaker]['polarity'].hist(ax=ax1, bins=20, color=colours[index], label=speaker, alpha=0.5)\n",
    "\n",
    "plt.title('Sentiment Histogram per Speaker')\n",
    "plt.xlabel(\"Polarity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-algeria",
   "metadata": {},
   "source": [
    "### ü¶ã Final task (optional): \n",
    "\n",
    "If you have finished everything else already, have a go at generating the last two graphs using the scores for subjectivity rather than the polarity. Remember to adjust the title and axes labels appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution for the mean subjectivity bar plot here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-faith",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    dfg = df.groupby(['speaker'])['subjectivity'].mean()\n",
    "    dfg.plot(color=['Green', 'Purple', 'Orange'], kind='bar', title='Mean Subjectivity Scores', ylabel='Subjectivity', xlabel='Speaker', figsize=(12, 9), rot=0)\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution for the subjectivity histogram here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-poverty",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    speakers = ['@Ira Glass','@Myron Jones','@Carol Jones']\n",
    "    colours = ['Purple','Orange','Green']\n",
    "\n",
    "    for index, speaker in enumerate(speakers):\n",
    "        df[df['speaker']==speaker]['subjectivity'].hist(ax=ax1, bins=20, color=colours[index], label=speaker, alpha=0.5)\n",
    "\n",
    "    plt.title('Sentiment Histogram per Speaker')\n",
    "    plt.xlabel(\"Subjectivity\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-evanescence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
