{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-palestinian",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "What you'll learn in this Notebook:\n",
    "\n",
    "- What sentiment analysis is\n",
    "- How it works\n",
    "- How to run it yourself\n",
    "- How to run it on a dataset and visualise the overall output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-washington",
   "metadata": {},
   "source": [
    "## 1. What is Sentiment Analysis and where is it used?\n",
    "\n",
    "Sentiment analyis is a computational technique used for analysing text to determine its sentiment, for example, whether the text is positively inflected, negatively inflected, or neutral.\n",
    "\n",
    "It is often used in commercial settings (and sometimes called opionion mining) and is applied to social media, online review data or surveys, for example, to determine automatically how customers or people express themselves about different brands or products and to analyse what positive and negative words they are using to express themselves.  During political elections sentiment analysis is also used to determine how people feel about different parties and candidates.\n",
    "\n",
    "Large amounts of social media data, like tweets from Twitter or posts on Reddit, can be analysed in this way to determine trends over time and to monitor opinions about whether things are working well or going wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-governor",
   "metadata": {},
   "source": [
    "## 2. How does it work?\n",
    "\n",
    "There are different methods used for performing sentiment analysis.  For example, there are lexicon-lookup methods where each word in a piece of text is checked automatically against a lexicon of positive and negative words to see if it appear in that lexicon. The more positive (or negative) words occur the stronger the positive (or negative) sentiment is considered to be.  In this course you will learn how to use a lexicon-based method.\n",
    "\n",
    "There are also machine learning and deep learning methods that can be applied to sentiment analysis. This is where data annotated for sentiment by humans is used to train a model, which can then be used to classify new data based on what it has learned during training.  We won't cover these approaches in this course, but if you are interested in such learning-based methods which are able to consider the context, as well as meaning representations of the words in the text mathematically, then check out the two sources below by Lui (2020) and Agarwal et al., (2020).\n" [BEA, THE TERM 'MEANING REPRESENTATIONS' ISN'T TRANSPARENT TO ME SO MIGHT CONFUSE SOME OF OUR STUDENTS TOO. CAN YOU REWORD? OR DOES THIS WORK AS AN ALTERNATIVE? 'representing the meanings of the words in the text mathematically'?],
    "\n",
    "- Liu, B., 2020. Sentiment analysis: Mining opinions, sentiments, and emotions. Cambridge University Press. https://doi.org/10.1017/9781108639286\n",
    "- Agarwal, B., Nayak, R., Mittal, N. and Patnaik, S. eds., 2020. Deep learning-based approaches for sentiment analysis. Singapore: Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-undergraduate",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis using TextBlob\n",
    "\n",
    "In this course you'll learn how to use TextBlob for sentiment analysis. TextBlob is a Python library developed to work with another natural language processing (NLP) tool called the Natural Language Toolkit ([NLTK](https://www.nltk.org)).  NLTK provides access to the lexicons which are required for computing sentiment. So TextBlob uses a lexicon-based approach for performing sentiment analysis.\n",
    "\n",
    "TextBlob computes sentiment using two values: polarity and subjectivity.  \n",
    "\n",
    "**Polarity** is a value between 1 and -1. The closer the value is to 1, the more positive the sentiment of the text is considered to be.  The closer the value is to -1, the more negative it is.  \n",
    "\n",
    "**Subjectivity** represents whether a piece of text is more of a personal opinion or something more factual. The subjectivity value lies between 0 and 1.  The closer it is to 1, the more subjective the text is, and the closer it is to 0 the more factual it is.\n",
    "\n",
    "Imagine your friend says to you ,\"I really hate this day. Everything is going wrong.\" The sentiment of their utterance is overall very negative in polarity, but their statement is also quite subjective.\n",
    "\n",
    "Let's see how TextBlob works in action ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-cooling",
   "metadata": {},
   "source": [
    "## 4. Running a Sentiment Analyser\n",
    "\n",
    "### Installing the tool\n",
    "\n",
    "You first need to install TextBlob, the sentiment analysis tool we're using on this course, onto your own computer. To install it you just need to run the following line of code.  Note that this may take a while and will generate some messages (and sometimes warnings) when installing all the libraries that are needed. Once the code cell finishes running (ie. the asterix in the square bracket changes to a number), move onto the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-egyptian",
   "metadata": {},
   "source": [
    "### Importing the tool\n",
    "\n",
    "Next you have to import the library like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-spice",
   "metadata": {},
   "source": [
    "### Running the tool\n",
    "\n",
    "You can run TextBlob on piece of text using just one line of code and store the output in the ```blob``` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"He's not happy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-quality",
   "metadata": {},
   "source": [
    "You can see that TextBlob is run by specifying an example sentence (\"He's not happy.\") in double quotes.  TextBlob computes various things besides sentiment, so to examine what the sentiment is you need to store it in a new variable (e.g. ``` results```), which you can then print:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = blob.sentiment\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-instrument",
   "metadata": {},
   "source": [
    "You can also compute sentiment for longer pieces of text. For example, let's check what it is for what our friend said earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"I really hate this day. Everything is going wrong.\")\n",
    "result = blob.sentiment\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-denmark",
   "metadata": {},
   "source": [
    "Look TextBlob classifies these two sentences as fairly negatively in terms of polarity but also as highly subjective.  Now let's try how TextBlob works with negtation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"I'm feeling not bad today.\")\n",
    "result = blob.sentiment\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-damage",
   "metadata": {},
   "source": [
    "It seems to recognise that there is negation in the sentence. Now try some other examples to see if that's always the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-weekend",
   "metadata": {},
   "source": [
    "### üêõ Mini task 4.1\n",
    "\n",
    "Try out your own examples. Use the code from the previous code cell but replace it with a different string of text, for example, \"Your pizzas are the best.\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-silver",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "blob = TextBlob(\"Your pizzas are the best.\")\n",
    "result = blob.sentiment\n",
    "print(result)\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-attack",
   "metadata": {},
   "source": [
    "## 5. Running TextBlob on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-parker",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "We now need to load our dataset into the notebook so that we can analyse it. We have put Act Three of the script into the data directory for you. Take a look in the Jupyter Notebook directory to see that you can find it. It's called ```Babysitting-Act3-cleaned.tsv```.\n",
    "\n",
    "To load the file, we will use a library called pandas. It can be used to read CSV and TSV files and store their information in column format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-facial",
   "metadata": {},
   "source": [
    "Our file contains two columns, the name of the speaker and what each speaker said, so the transcript text.\n",
    "\n",
    "Pandas let's us read in the file as a data frame (like a table) using the ```read_table``` function. \n",
    "\n",
    "We can specify the names of the columns using the ```colnames``` variable and the column separator ```sep``` (set to \"t\" for tab in this case).\n",
    "\n",
    "We store this table in the ```df``` variable, short for data frame.\n",
    "\n",
    "We also specify that the values in the text and speaker columns are strings.  We need to do this as TextBlob only runs on strings as input.\n",
    "\n",
    "The last line (```df.head()```) of code shows the header and the first five rows of the data frame we just created and loaded in pandas. Yeah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the file as a table using pandas\n",
    "colnames=['speaker', 'text'] \n",
    "df = pd.read_table(\"./data/Babysitting-Act3-cleaned.tsv\", sep=\"\\t\", names=colnames)\n",
    "df['text'] = df['text'].astype(str)\n",
    "df['speaker'] = df['speaker'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-spain",
   "metadata": {},
   "source": [
    "Because the speakers speak longer and shorter utterances, let's split the transcript into sentences before computing sentiment.\n",
    "\n",
    "The following bit of code is a simple sentence splitter which splits each transcipt at punctuation marks and expands the data frame to include one row for each sentence which each speaker said.\n",
    "\n",
    "The last line instructs to print the first 25 rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (df.pop('text')\n",
    "    .str.strip('.')\n",
    "    .str.strip('?')\n",
    "    .str.strip('!')\n",
    "    .str.split('[\\.\\?\\!]\\s+', expand=True)\n",
    "    .stack()\n",
    "    .rename('text')\n",
    "    .reset_index(level=1, drop=True))\n",
    "\n",
    "df = df.join(s).reset_index(drop=True)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-indonesian",
   "metadata": {},
   "source": [
    "You can see an index for each line in the table on the left as well as the two columns, speaker and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-pepper",
   "metadata": {},
   "source": [
    "You can use the ```describe()``` function to give you a summary of what's in the table. When you run the next line of code you will see that the table contains 364 rows and there are three unique speakers.  The speaker uttering the most sentences is Myron Jones and the most frequent bit of spoken text is ```Yeah```. Yeah. :-)\n",
    "\n",
    "The text is what we want to compute sentiment for. Let's do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-diamond",
   "metadata": {},
   "source": [
    "### Computing sentiment \n",
    "\n",
    "We will now compute the sentiment for each row of text.\n",
    "\n",
    "To do this we use two lambda functions to determine the polarity and subjectivity for each line of text in the data frame.\n",
    "\n",
    "**Lambda function** is a small anonymous function in Python.  It can take any number of arguments, but can only have one expression.\n",
    "\n",
    "We apply the lambda functions to each text cell in the data frame and store their results in the data frame as two additional columns called polarity and subjectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing polarity and subjectivity for each line in the 'text' column\n",
    "polarity = lambda x: TextBlob(x).sentiment.polarity\n",
    "subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "df['polarity'] = df['text'].apply(polarity)\n",
    "df['subjectivity'] = df['text'].apply(subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-paste",
   "metadata": {},
   "source": [
    "### üêõ Minitask 5.1 \n",
    "\n",
    "Now check how the first few lines of the data frame look like.  Remember you can use the ```head()``` function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-monitor",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    " df.head()\n",
    " \n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-raise",
   "metadata": {},
   "source": [
    "## 6. Visualising sentiment\n",
    "\n",
    "Now let's visualise sentiment so that we can display and understand the results a bit better.\n",
    "\n",
    "### Visualising each result by colour\n",
    "\n",
    "The following line of code visualises the polarity and subjectivity in the table using colours. It's quite a long line of code but all it does is set a colour background to the cells containing the sentiment scores.\n",
    "\n",
    "Polarity is displayed as a colour ranging between red, yellow and green, <font color=\"red\">red</font> signaling negative sentiment, <font color=\"green\">green</font> signalling positive sentiment and <font color=\"gold\">light orange</font> being neutral.  Subjectivity is displayed on a gray scale with white signalling factual statements and black subjective ones.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-genre",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.style.background_gradient(subset='polarity', cmap='RdYlGn', axis=None).background_gradient(subset=['subjectivity'], cmap='Greys', axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-outreach",
   "metadata": {},
   "source": [
    "### üêõ Mini task 6.1\n",
    "\n",
    "Look at a few individual results and check why they might be either positive or negative by looking at the vocabulary used. Can you spot any examples where the sentiment analysis looks accurate or where it went wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-curtis",
   "metadata": {},
   "source": [
    "### Visualising sentiment in one graph\n",
    "\n",
    "We will now display the sentiment results for the entire data set in one graph. We'll plot polarity on the x-axis and subjectivity on the y-axis.\n",
    "\n",
    "You don't need to understand the following bit of code in detail, though I've added some explanations in the comments.  One thing to know is that we use a library called ```matplotlib``` for creating the graphs. The does is go through the data frame to collect all the scores, store them in a list and display them on the graph with each bit of text as one polarity/subjectivity coordinate.\n",
    "\n",
    "The code also keeps track whenever the same coordinates are repeated so that pairs which occur frequently will be displayed larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results in one graph showing:\n",
    "# subjectivity on the y-axis\n",
    "# polarity on the x-axis\n",
    "\n",
    "# import matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# set up the size of the figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "# create two empty lists for the x and y coordinates\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "# add the polarity values as x coordinates and\n",
    "# the subjectivity values as the y coordinates\n",
    "for (index, row) in df.iterrows():\n",
    "    x.append(row.loc['polarity'])\n",
    "    y.append(row.loc['subjectivity'])\n",
    "\n",
    "# increase the dot size in case there are multiple coordinate pairs\n",
    "from collections import Counter\n",
    "# count the occurrences of each point\n",
    "c = Counter(zip(x,y))\n",
    "# create a list of the sizes, here multiplied by 10 for scale\n",
    "s = [10*c[(xx,yy)] for xx,yy in zip(x,y)]\n",
    "\n",
    "# make the scatter plot using gray as the colour for each dot\n",
    "plt.scatter(x, y, s, color='Gray')\n",
    "\n",
    "# specify the title\n",
    "plt.title('Sentiment Analysis', fontsize = 20)\n",
    "\n",
    "# set lables on axes\n",
    "plt.xlabel('‚Üê Negative ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî Positive ‚Üí', fontsize=15)\n",
    "plt.ylabel('‚Üê Facts ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî Opinions ‚Üí', fontsize=15)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-patrol",
   "metadata": {},
   "source": [
    "Assuming that the sentiment analysis performs more or less correctly, we can conclude from this graph that, aside from the neutral utterances, the dataset is tending towards beeing slightly more positive than negative and it's slightly more subjective than factual.\n",
    "\n",
    "When companies do this kind of analysis they will be interested in these kind of trends and how they change over time but they will also want to see examples of particular outliers to see what customers are happy or unhappy about in terms of products and services.\n",
    "\n",
    "When doing literary analysis, we want to go further and examine sentiment by character or speaker. As we know the speaker for each bit of text in the data set, we can do this very easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-smith",
   "metadata": {},
   "source": [
    "### Visualising sentiment by speaker\n",
    "\n",
    "Here we create the same graph but using a different colour for each speaker.  Our data set contains three speakers: <font color=\"purple\">Ira Glass</font>, <font color=\"orange\">Myron Jones</font> and <font color=\"green\">Carol Jones</font>.\n",
    "\n",
    "You don't need to understand the following bit of code in detail, though I've added some explanations in the comments.  Essentially the only difference to the previous cell is that the code collects the data by speaker first before it plots it in the different colours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis by speaker\n",
    "\n",
    "# set up the size of the figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "# create empty x and y coordinate lists for each of the three speakers\n",
    "ira_x=[]\n",
    "ira_y=[]\n",
    "myron_x=[]\n",
    "myron_y=[]\n",
    "carol_x=[]\n",
    "carol_y=[]\n",
    "\n",
    "# loop through the data frame and assign the x and y coordinates\n",
    "# to the correct list depending on the speaker\n",
    "for (index, row) in df.iterrows():\n",
    "    x=row.loc['polarity']\n",
    "    y=row.loc['subjectivity']\n",
    "    speaker=row.loc['speaker']\n",
    "    if speaker == \"@Ira Glass\":\n",
    "        ira_x.append(x)\n",
    "        ira_y.append(y)\n",
    "    elif speaker == \"@Myron Jones\":\n",
    "        myron_x.append(x)\n",
    "        myron_y.append(y)\n",
    "    elif speaker == \"@Carol Jones\":\n",
    "        carol_x.append(x)\n",
    "        carol_y.append(y)\n",
    "\n",
    "# function to increase the dot size in case there are multiple coordinate pairs      \n",
    "def getSize(x,y):\n",
    "    # count the occurrences of each point\n",
    "    c = Counter(zip(x,y))\n",
    "    # create a list of the sizes, here multiplied by 10 for scale\n",
    "    s = [10*c[(xx,yy)] for xx,yy in zip(x,y)]\n",
    "    return s\n",
    "\n",
    "# create scatter plots per speaker\n",
    "ira = plt.scatter(ira_x, ira_y, s=getSize(ira_x,ira_y), color='Purple')\n",
    "myron = plt.scatter(myron_x, myron_y, s=getSize(myron_x,myron_y), color='Orange')\n",
    "carol = plt.scatter(carol_x, carol_y, s=getSize(carol_x,carol_y), color='Green')\n",
    "\n",
    "# specify the title\n",
    "plt.title('Sentiment Analysis per Speaker', fontsize = 20)\n",
    "\n",
    "# set lables of axes\n",
    "plt.xlabel('‚Üê Negative ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî Positive ‚Üí', fontsize=15)\n",
    "plt.ylabel('‚Üê Facts ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî Opinions ‚Üí', fontsize=15)\n",
    "\n",
    "# add legend\n",
    "lgnd = plt.legend((ira, myron, carol),\n",
    "           ('Ira Glass', 'Myron Jones', 'Carol Jones'),\n",
    "           loc='lower right')\n",
    "lgnd.set_title(\"Speakers\")\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([50.0])\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-temperature",
   "metadata": {},
   "source": [
    "You can see that Carol is slightly more positive and subjective than Ira and Myron, although she's also speaking the least. You can work this out mathematically by determining the average scores per speaker and plot them in a bar plot. This is done by grouping the data frame by speaker and polarity (or subjectivity) using the ```groupby()``` function. We'll first plot mean polarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate mean of sentiment score per speaker\n",
    "dfg = df.groupby(['speaker'])['polarity'].mean()\n",
    "\n",
    "#create a bar plot\n",
    "dfg.plot(color=['Green', 'Purple', 'Orange'], kind='bar', title='Mean Polarity Scores', ylabel='Polarity',\n",
    "         xlabel='Speaker', figsize=(12, 9), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-district",
   "metadata": {},
   "source": [
    "You can also plot the sentiment as a histogram and get a better idea of distribution of the scores per speaker. This shows that Carol Jones is most spread out in terms of her polarity, Myron Jones is saying mostly neutral to slightly positive things. Ira Glass is mostly neutral which makes sense, her being the interviewer. You can see how this kind of analysis can be used to build up profiles of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "speakers = ['@Ira Glass','@Myron Jones','@Carol Jones']\n",
    "colours = ['Purple','Orange','Green']\n",
    "\n",
    "for index, speaker in enumerate(speakers):\n",
    "    df[df['speaker']==speaker]['polarity'].hist(ax=ax1, bins=20, color=colours[index], label=speaker, alpha=0.5)\n",
    "\n",
    "plt.title('Sentiment Histogram per Speaker')\n",
    "plt.xlabel(\"Polarity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-algeria",
   "metadata": {},
   "source": [
    "### ü¶ã Extra task 6.2 (optional): \n",
    "\n",
    "If you have finished everything else already, display the last two graphs but for subjectivity. Remember to adjust the title and axes labels appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution for the mean subjectivity bar plot here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-faith",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    " dfg = df.groupby(['speaker'])['subjectivity'].mean()\n",
    "\n",
    " dfg.plot(color=['Green', 'Purple', 'Orange'], kind='bar', title='Mean Subjectivity Scores', ylabel='Subjectivity', xlabel='Speaker', figsize=(12, 9), rot=0)\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution for the subjectivity histogram here ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-poverty",
   "metadata": {},
   "source": [
    "<details><summary style='color:blue'>CLICK HERE TO SEE THE THE ANSWER. BUT REALLY TRY TO DO IT YOURSELF FIRST!</summary>\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "speakers = ['@Ira Glass','@Myron Jones','@Carol Jones']\n",
    "colours = ['Purple','Orange','Green']\n",
    "\n",
    "for index, speaker in enumerate(speakers):\n",
    "    df[df['speaker']==speaker]['subjectivity'].hist(ax=ax1, bins=20, color=colours[index], label=speaker, alpha=0.5)\n",
    "\n",
    "plt.title('Sentiment Histogram per Speaker')\n",
    "plt.xlabel(\"Subjectivity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-evanescence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
